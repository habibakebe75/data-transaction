Data Transactions Pipeline â€“ Projet de dÃ©monstration
Auteur : Habiba Kebe
ğŸ“§ Email : habibakebe75@gmail.com
ğŸ“± TÃ©lÃ©phone : 07 81 15 94 60


ğŸ¯ Objectif du projet
Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre de ma prÃ©paration Ã  une POEI Data / Cloud / IA.
Il simule un vrai pipeline de donnÃ©es utilisÃ© en entreprise, inspirÃ© de mon expÃ©rience dans le test logiciel (QA).
Lâ€™objectif est de :
Charger des transactions brutes depuis un fichier CSV
Nettoyer et transformer les donnÃ©es
VÃ©rifier leur qualitÃ© avec des rÃ¨gles simples
Calculer automatiquement le total des montants par client
Exporter un fichier propre, utilisable par les Ã©quipes Data / mÃ©tiers
Ajouter des tests automatisÃ©s pour assurer la qualitÃ© des donnÃ©es
Ce projet reflÃ¨te les missions essentielles dâ€™un Data Engineer junior :
âœ”ï¸ Nettoyage de donnÃ©es
âœ”ï¸ QualitÃ© des donnÃ©es
âœ”ï¸ Transformation (ETL)
âœ”ï¸ Automatisation
âœ”ï¸ Tests et validation

ğŸ§© Contexte mÃ©tier
On simule un cas rÃ©el en environnement bancaire :
Une application gÃ©nÃ¨re chaque jour un fichier CSV contenant :
transaction_id
client_id
date
montant
Le rÃ´le du pipeline :
Charger le fichier CSV
Nettoyer les donnÃ©es invalides (client manquant, montant incorrect, etc.)
Appliquer des rÃ¨gles de qualitÃ©
Identifier les anomalies (ex : montants nÃ©gatifs)
Calculer le total des montants par client
Sauvegarder les rÃ©sultats dans un nouveau fichier

ğŸ› ï¸ CompÃ©tences dÃ©montrÃ©es
Python
Pandas
Nettoyage et transformation de donnÃ©es (ETL)
QualitÃ© des donnÃ©es
Tests automatisÃ©s (pytest)
Organisation dâ€™un mini-pipeline
Structuration dâ€™un projet Data
